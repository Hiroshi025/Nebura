{"version":3,"file":"google.service.js","sources":["src/application/services/asistent/google.service.ts"],"sourceRoot":"/","sourcesContent":["import { GoogleGenerativeAI, Part } from \"@google/generative-ai\";\r\nimport { GeminiOptions, GeminiResponse } from \"@typings/modules/api\";\r\n\r\n/**\r\n * Service for interacting with Google Gemini Generative AI.\r\n *\r\n * Provides methods to process text, files, or a combination of both using the Gemini API.\r\n *\r\n * @see [Google Generative AI Documentation](https://ai.google.dev/)\r\n */\r\nexport class GeminiService {\r\n  private genAI!: GoogleGenerativeAI;\r\n\r\n  /**\r\n   * Processes a text prompt using the Gemini Generative AI model.\r\n   *\r\n   * @param text - The text prompt to send to the model.\r\n   * @param options - Configuration options including API key, model, and system instructions.\r\n   * @returns A promise that resolves to a GeminiResponse containing the model's output and metadata.\r\n   *\r\n   * @see [Gemini API Reference](https://ai.google.dev/api/rest/)\r\n   *\r\n   * @example\r\n   * ```typescript\r\n   * const response = await geminiService.processText(\"Hello, Gemini!\", options);\r\n   * ```\r\n   */\r\n  async textGoogle(text: string, options: GeminiOptions): Promise<GeminiResponse> {\r\n    this.genAI = new GoogleGenerativeAI(options.apiKey);\r\n    const model = this.genAI.getGenerativeModel({\r\n      model: options.model,\r\n      systemInstruction: options.systemInstruction,\r\n    });\r\n\r\n    const result = await model.generateContent(text);\r\n    const responseText = await result.response.text();\r\n\r\n    return {\r\n      response: responseText,\r\n      model: options.model,\r\n      timestamp: new Date(),\r\n      userTokenHash: options.apiKeyHash,\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Processes a file (such as a document or image) using the Gemini Generative AI model.\r\n   *\r\n   * The file is encoded in base64 and sent as inline data to the model, along with an optional prompt.\r\n   *\r\n   * @param file - The file buffer to process.\r\n   * @param mimeType - The MIME type of the file (e.g., \"application/pdf\", \"image/png\").\r\n   * @param promptText - Optional text prompt to provide context for the file.\r\n   * @param options - Configuration options including API key, model, and system instructions.\r\n   * @returns A promise that resolves to a GeminiResponse containing the model's output and metadata.\r\n   *\r\n   * @see [Supported File Types](https://ai.google.dev/docs/supported_files)\r\n   *\r\n   * @example\r\n   * ```typescript\r\n   * const response = await geminiService.processFile(fileBuffer, \"application/pdf\", \"Summarize this document\", options);\r\n   * ```\r\n   */\r\n  async fileGoogle(\r\n    file: Buffer,\r\n    mimeType: string,\r\n    promptText: string,\r\n    options: GeminiOptions,\r\n  ): Promise<GeminiResponse> {\r\n    this.genAI = new GoogleGenerativeAI(options.apiKey);\r\n    const model = this.genAI.getGenerativeModel({\r\n      model: options.model,\r\n      systemInstruction: options.systemInstruction,\r\n    });\r\n\r\n    const fileData: Part = {\r\n      inlineData: { data: file.toString(\"base64\"), mimeType },\r\n      // Removed mimeType as it is not valid for InlineDataPart\r\n    };\r\n\r\n    const contents: Part[] = [\r\n      {\r\n        inlineData: {\r\n          data: Buffer.from(promptText || \"Process this document\").toString(\"base64\"),\r\n          mimeType: \"text/plain\",\r\n        },\r\n      },\r\n      fileData,\r\n    ];\r\n\r\n    const result = await model.generateContent(contents);\r\n    const responseText = await result.response.text();\r\n\r\n    return {\r\n      response: responseText,\r\n      model: options.model,\r\n      timestamp: new Date(),\r\n      userTokenHash: options.apiKeyHash,\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Processes both a text prompt and a file together using the Gemini Generative AI model.\r\n   *\r\n   * Useful for scenarios where the model should consider both textual and file-based input.\r\n   *\r\n   * @param text - The text prompt to send to the model.\r\n   * @param file - The file buffer to process.\r\n   * @param mimeType - The MIME type of the file.\r\n   * @param options - Configuration options including API key, model, and system instructions.\r\n   * @returns A promise that resolves to a GeminiResponse containing the model's output and metadata.\r\n   *\r\n   * @example\r\n   * ```typescript\r\n   * const response = await geminiService.processCombined(\"Analyze this image\", imageBuffer, \"image/png\", options);\r\n   * ```\r\n   */\r\n  async combinedGoogle(\r\n    text: string,\r\n    file: Buffer,\r\n    mimeType: string, // quitar el guion bajo para usar el par√°metro\r\n    options: GeminiOptions,\r\n  ): Promise<GeminiResponse> {\r\n    this.genAI = new GoogleGenerativeAI(options.apiKey);\r\n    const model = this.genAI.getGenerativeModel({\r\n      model: options.model,\r\n      systemInstruction: options.systemInstruction,\r\n    });\r\n\r\n    const fileData: Part = {\r\n      inlineData: { data: file.toString(\"base64\"), mimeType }, // usar el mimeType recibido\r\n    };\r\n\r\n    const contents: Part[] = [\r\n      { inlineData: { data: Buffer.from(text).toString(\"base64\"), mimeType: \"text/plain\" } },\r\n      fileData,\r\n    ];\r\n\r\n    const result = await model.generateContent(contents);\r\n    const responseText = await result.response.text();\r\n\r\n    return {\r\n      response: responseText,\r\n      model: options.model,\r\n      timestamp: new Date(),\r\n      userTokenHash: options.apiKeyHash,\r\n    };\r\n  }\r\n}\r\n"],"names":[],"mappings":";;;;;AAAA,yDAAiE;AAGjE;;;;;;GAMG;AACH,MAAa,aAAa;IAChB,KAAK,CAAsB;IAEnC;;;;;;;;;;;;;OAaG;IACH,KAAK,CAAC,UAAU,CAAC,IAAY,EAAE,OAAsB;QACnD,IAAI,CAAC,KAAK,GAAG,IAAI,kCAAkB,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACpD,MAAM,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC,kBAAkB,CAAC;YAC1C,KAAK,EAAE,OAAO,CAAC,KAAK;YACpB,iBAAiB,EAAE,OAAO,CAAC,iBAAiB;SAC7C,CAAC,CAAC;QAEH,MAAM,MAAM,GAAG,MAAM,KAAK,CAAC,eAAe,CAAC,IAAI,CAAC,CAAC;QACjD,MAAM,YAAY,GAAG,MAAM,MAAM,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;QAElD,OAAO;YACL,QAAQ,EAAE,YAAY;YACtB,KAAK,EAAE,OAAO,CAAC,KAAK;YACpB,SAAS,EAAE,IAAI,IAAI,EAAE;YACrB,aAAa,EAAE,OAAO,CAAC,UAAU;SAClC,CAAC;IACJ,CAAC;IAED;;;;;;;;;;;;;;;;;OAiBG;IACH,KAAK,CAAC,UAAU,CACd,IAAY,EACZ,QAAgB,EAChB,UAAkB,EAClB,OAAsB;QAEtB,IAAI,CAAC,KAAK,GAAG,IAAI,kCAAkB,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACpD,MAAM,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC,kBAAkB,CAAC;YAC1C,KAAK,EAAE,OAAO,CAAC,KAAK;YACpB,iBAAiB,EAAE,OAAO,CAAC,iBAAiB;SAC7C,CAAC,CAAC;QAEH,MAAM,QAAQ,GAAS;YACrB,UAAU,EAAE,EAAE,IAAI,EAAE,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAAC,EAAE,QAAQ,EAAE;YACvD,yDAAyD;SAC1D,CAAC;QAEF,MAAM,QAAQ,GAAW;YACvB;gBACE,UAAU,EAAE;oBACV,IAAI,EAAE,MAAM,CAAC,IAAI,CAAC,UAAU,IAAI,uBAAuB,CAAC,CAAC,QAAQ,CAAC,QAAQ,CAAC;oBAC3E,QAAQ,EAAE,YAAY;iBACvB;aACF;YACD,QAAQ;SACT,CAAC;QAEF,MAAM,MAAM,GAAG,MAAM,KAAK,CAAC,eAAe,CAAC,QAAQ,CAAC,CAAC;QACrD,MAAM,YAAY,GAAG,MAAM,MAAM,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;QAElD,OAAO;YACL,QAAQ,EAAE,YAAY;YACtB,KAAK,EAAE,OAAO,CAAC,KAAK;YACpB,SAAS,EAAE,IAAI,IAAI,EAAE;YACrB,aAAa,EAAE,OAAO,CAAC,UAAU;SAClC,CAAC;IACJ,CAAC;IAED;;;;;;;;;;;;;;;OAeG;IACH,KAAK,CAAC,cAAc,CAClB,IAAY,EACZ,IAAY,EACZ,QAAgB,EAAE,8CAA8C;IAChE,OAAsB;QAEtB,IAAI,CAAC,KAAK,GAAG,IAAI,kCAAkB,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACpD,MAAM,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC,kBAAkB,CAAC;YAC1C,KAAK,EAAE,OAAO,CAAC,KAAK;YACpB,iBAAiB,EAAE,OAAO,CAAC,iBAAiB;SAC7C,CAAC,CAAC;QAEH,MAAM,QAAQ,GAAS;YACrB,UAAU,EAAE,EAAE,IAAI,EAAE,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAAC,EAAE,QAAQ,EAAE,EAAE,4BAA4B;SACtF,CAAC;QAEF,MAAM,QAAQ,GAAW;YACvB,EAAE,UAAU,EAAE,EAAE,IAAI,EAAE,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,QAAQ,CAAC,QAAQ,CAAC,EAAE,QAAQ,EAAE,YAAY,EAAE,EAAE;YACtF,QAAQ;SACT,CAAC;QAEF,MAAM,MAAM,GAAG,MAAM,KAAK,CAAC,eAAe,CAAC,QAAQ,CAAC,CAAC;QACrD,MAAM,YAAY,GAAG,MAAM,MAAM,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;QAElD,OAAO;YACL,QAAQ,EAAE,YAAY;YACtB,KAAK,EAAE,OAAO,CAAC,KAAK;YACpB,SAAS,EAAE,IAAI,IAAI,EAAE;YACrB,aAAa,EAAE,OAAO,CAAC,UAAU;SAClC,CAAC;IACJ,CAAC;CACF;AA1ID,sCA0IC","debug_id":"c11b5572-24a1-509e-9d51-cc7804421870"}